# Medical_Diagnosis_attention_mechanism
This project explores how BERT (Bidirectional Encoder Representations from Transformers) processes and attends to key medical symptoms in patient notes. By extracting attention scores from BERTâ€™s hidden layers, we generate attention heatmaps to visualize which words the model focuses on while interpreting medical descriptions.
